---
layout: post
title: Always report effect size!
subtitle: P value is not enough by Alex Javidi
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [books, test]
---

Let's start by a quick literature review:

> I have learned and taught that the primary product of a research inquiry is one or more measures of effect size, not p values. Effect-size measures include mean differences (raw or standardized), correlations and squared correlation of all kinds, odds ratios, kappas-whatever conveys the magnitude of the phenomenon of interest appropriate to the reseach context.

[Things I have learned (so far)](https://psycnet.apa.org/doiLanding?doi=10.1037%2F0003-066X.45.12.1304)

> Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical significance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies.
 
 [Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3840331/)

 