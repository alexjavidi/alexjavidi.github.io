---
layout: post
title: Effect Size
subtitle: Why P Value is Not Enough
#cover-img: /assets/img/path.jpg
#thumbnail-img: /assets/img/measure-1509707_640.jpg
#share-img: /assets/img/path.jpg
tags: [statistics, significance, effect-size]
---

Effect size is one of the most importat outcomes of an empirical study. Let us start by a quick literature review:

> Practically every empirical study is looking for an effect. Effect sizes quantify the magnitude of the effect that emerges from the sampled data. Thus, they are the currency of psychological research. Effect sizes can be unstandardized measures such as the difference between two means, but more often they are standardized, which makes them independent of a study’s scales and instruments, making it in principal possible to compare different domains and approaches.

[The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases
](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813/full)


> ‘Effect size’ is simply a way of quantifying the size of the difference between 
two groups. It is easy to calculate, readily understood and can be applied to any 
measured outcome in Education or Social Science. It is particularly valuable for
quantifying the effectiveness of a particular intervention, relative to some comparison.
It allows us to move beyond the simplistic, ‘Does it work or not?’ to the far more 
sophisticated, ‘How well does it work in a range of contexts?’ Moreover, by placing 
the emphasis on the most important aspect of an intervention – the size of the effect – 
rather than its statistical significance (which conflates effect size and sample size), it 
promotes a more scientific approach to the accumulation of knowledge. For these 
reasons, effect size is an important tool in reporting and interpreting effectiveness.

[It's the Effect Size, Stupid](https://f.hubspotusercontent30.net/hubfs/5191137/attachments/ebe/ESguide.pdf)

> Statistical significance is the least interesting thing about the results. You should describe the results in terms of measures of magnitude—not just, does a treatment affect people, but how much does it affect them.
 
 [Beyond significance testing: Reforming data analysis methods in behavioral research](https://psycnet.apa.org/record/2004-13019-000)

> I have learned and taught that the primary product of a research inquiry is one or more measures of effect size, not p values. Effect-size measures include mean differences (raw or standardized), correlations and squared correlation of all kinds, odds ratios, kappas-whatever conveys the magnitude of the phenomenon of interest appropriate to the reseach context.

[Things I have learned (so far)](https://tech.me.holycross.edu/files/2015/03/Cohen_1990.pdf)

> Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical significance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies.
 
 [Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3840331/)


 By: Alex Javidi
